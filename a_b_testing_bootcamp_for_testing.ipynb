{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BO95H7sbAqHB"
   },
   "source": [
    "# A/B Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is A/B testing?\n",
    "\n",
    "Although well-chosen data visualizations can help uncover interesting *correlations* in our data, they cannot demonstrate *causality*. Fortunately, we can set up **randomized experiments** in order to do this. We'll look at one of the simplest versions, the **A/B test**.\n",
    "\n",
    "We'll be working with data from an experiment conducted by Scott W. H. Young from Montana State University in 2013. We won't be replicating the entire research project, but focus on the parts which help us develop better intuition about how A/B tests can be useful to us in general.\n",
    "\n",
    "You can find the dataset [here](https://scholarworks.montana.edu/xmlui/handle/1/3507), and the article [here](https://quod.lib.umich.edu/w/weave/12535642.0001.101?view=text;rgn=main#N3) if you want to learn more (note that our results won't necessarily match those of the authors due to differences how we define the response variables).\n",
    "\n",
    "The experiment wished to test how implementing slight modifications to the University's library homepage would affect user engagement with the \"Interact\" category, which offered person-to-person assistance and support on topics related to the library. This category had been neglected by users in the past, and management's main goal was to increase clicks and user retention."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring our options\n",
    "\n",
    "This was the original homepage:\n",
    "\n",
    "![alt](data/images/interact_original.png \"Interact, original\")\n",
    "\n",
    "Management decided that they wanted to test several variants of the name of the category, to see which one would attract the most users. The alternatives they considered were:\n",
    "\n",
    "* **Interact** (the default category, hence the \"control\"), indexed as `/index.php`\n",
    "* **Connect** (variant 1), indexed as `/index2.php`\n",
    "* **Learn** (variant 2), indexed as `/index3.php`\n",
    "* **Help** (variant 3), indexed as `/index4.php`\n",
    "* **Services** (variant 4), indexed as `/index5.php`\n",
    "\n",
    "They asked the web design team to come up with alternative homepages. This is the relevant part of the homepage for variant 1:\n",
    "\n",
    "![alt](data/images/connect_original.png \"Connect, original\")\n",
    "\n",
    "For variant 2:\n",
    "\n",
    "![alt](data/images/learn_original.png \"Learn, original\")\n",
    "\n",
    "For variant 3:\n",
    "\n",
    "![alt](data/images/help_original.png \"Help, original\")\n",
    "\n",
    "For variant 4:\n",
    "\n",
    "![alt](data/images/services_original.png \"Services, original\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this test is a *multi-branched* experiment. A/B tests is a term usually reserved for one-branched tests (one control and one treatment) - when there are several treatment groups, they are called multi-branched tests. However, the logic is exactly the same, only with more than one variant to try.\n",
    "\n",
    "We've just defined our treatment variables. To keep things simple, our response variable will be the click-through rate. This rate tells you the clicks a link received as a percentage of the total number of clicks on the page. So if the homepage received, say, 500 clicks in a given time period, and the link got 20 clicks, then that link's click-through rate was 20/500 = 4%.\n",
    "\n",
    "There are tools that make running an A/B test on a webpage very streamlined and efficient, like [Google Optimize](https://support.google.com/optimize/answer/6211930?hl=en), [CrazyEgg](https://www.crazyegg.com/ab-testing) and [Matomo](https://matomo.org/docs/ab-testing/). We won't use any of those here, but you are free to look into them if you'd like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The control group\n",
    "\n",
    "The team collected data between May 29, 2013 and June 18, 2013 (a three-week period) with CrazyEgg. Users were randomly assigned to one of the five alternatives (either control or one of the four variants) when they visited the webpage.\n",
    "\n",
    "Let's see how the users interacted with each link in the homepage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Interact (control)\n",
    "interact = pd.read_csv('data/interact.csv')\n",
    "# Connect\n",
    "connect = pd.read_csv('data/connect.csv')\n",
    "# Learn\n",
    "learn = pd.read_csv('data/learn.csv')\n",
    "# Help\n",
    "help_data = pd.read_csv('data/help.csv')\n",
    "# Services\n",
    "services = pd.read_csv('data/services.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These files contain clicks per link for each variant. Let's examine the control group metrics (Interact) and plot them as a pie chart. The columns that interest us are `Name` and `No. clicks`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of clicks was:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(interact['No. clicks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interact = interact[interact['Visible?']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The pie chart\n",
    "categories = ['FIND', 'Search', 'REQUEST', 'INTERACT']\n",
    "interact_reduced = interact[interact['Name'].isin(categories)]\n",
    "interact_reduced = interact_reduced.groupby('Name')['No. clicks'].sum()\n",
    "others = pd.Series(sum(interact['No. clicks']) - sum(interact_reduced), index=['Others'])\n",
    "interact_reduced = interact_reduced.append(others)\n",
    "interact_reduced.plot.pie(figsize=(5, 5), autopct='%1.1f%%', pctdistance=1.3, labeldistance=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at a heatmap of click actions, which allow us to visualize exactly where and how frequently users interacted with various parts of a webpage:\n",
    "\n",
    "![alt](data/images/interact_heatmap.jpg \"Interact, heatmap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variant 1 (Connect)\n",
    "\n",
    "Let's do the same with variant 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(connect['No. clicks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "connect = connect[connect['Visible?']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The pie chart\n",
    "categories = ['FIND', 'Search', 'REQUEST', 'CONNECT']\n",
    "connect_reduced = connect[connect['Name'].isin(categories)]\n",
    "connect_reduced = connect_reduced.groupby('Name')['No. clicks'].sum()\n",
    "others = pd.Series(sum(connect['No. clicks']) - sum(connect_reduced), index=['Others'])\n",
    "connect_reduced = connect_reduced.append(others)\n",
    "connect_reduced.plot.pie(figsize=(5, 5), autopct='%1.1f%%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connect drives our click-through rate up. The heatmap is:\n",
    "\n",
    "![alt](data/images/connect_heatmap.jpg \"Connect, heatmap\")\n",
    "\n",
    "Let's see if the other variants have good results as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variant 2 (Learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(learn['No. clicks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = learn[learn['Visible?']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The pie chart\n",
    "categories = ['FIND', 'Search', 'REQUEST', 'LEARN']\n",
    "learn_reduced = learn[learn['Name'].isin(categories)]\n",
    "learn_reduced = learn_reduced.groupby('Name')['No. clicks'].sum()\n",
    "others = pd.Series(sum(learn['No. clicks']) - sum(learn_reduced), index=['Others'])\n",
    "learn_reduced = learn_reduced.append(others)\n",
    "learn_reduced.plot.pie(figsize=(5, 5), autopct='%1.1f%%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the heatmap:\n",
    "    \n",
    "![alt](data/images/learn_heatmap.jpg \"Learn, heatmap\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variant 3 (Help)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(help_data['No. clicks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help_data = help_data[help_data['Visible?']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The pie chart\n",
    "categories = ['FIND', 'Search', 'REQUEST', 'HELP']\n",
    "help_data_reduced = help_data[help_data['Name'].isin(categories)]\n",
    "help_data_reduced = help_data_reduced.groupby('Name')['No. clicks'].sum()\n",
    "others = pd.Series(sum(help_data['No. clicks']) - sum(help_data_reduced), index=['Others'])\n",
    "help_data_reduced = help_data_reduced.append(others)\n",
    "help_data_reduced.plot.pie(figsize=(5, 5), autopct='%1.1f%%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is larger than the control group but lower than variant 1 (Connect):\n",
    "\n",
    "![alt](data/images/help_heatmap.jpg \"Help, heatmap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variant 4 (Services)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(services['No. clicks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "services = services[services['Visible?']==True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The pie chart\n",
    "categories = ['FIND', 'Search', 'REQUEST', 'SERVICES']\n",
    "services_reduced = services[services['Name'].isin(categories)]\n",
    "services_reduced = services_reduced.groupby('Name')['No. clicks'].sum()\n",
    "others = pd.Series(sum(services['No. clicks']) - sum(services_reduced), index=['Others'])\n",
    "services_reduced = services_reduced.append(others)\n",
    "services_reduced.plot.pie(figsize=(5, 5), autopct='%1.1f%%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the heatmap:\n",
    "\n",
    "![alt](data/images/services_heatmap.jpg \"Services, heatmap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This performs at the same level as Connect. The final results are:\n",
    "\n",
    "| Variant       | Text     | Click-through rate |\n",
    "|---------------|----------|--------------------|\n",
    "| Control group | Interact | 1.8                |\n",
    "| Variant 1     | Connect  | 3.6                |\n",
    "| Variant 2     | Learn    | 1.4                |\n",
    "| Variant 3     | Help     | 2.4                |\n",
    "| Variant 4     | Services | 3.5                |\n",
    "\n",
    "From what we see in this table, the best options, in order, are Connect, Services, Help, Interact and Learn. It could be argued that the difference between Services and Connect isn't really so big so as to prefer one over the other. That is why A/B tests routinely make use of tests of statistical significance to address precisely this concern. You'll be learning about these sorts of statistical tests in future cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "tracer": "3.7.0-SNAPSHOT-57c20131aabc1dc2a8c675852d80a7da"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
